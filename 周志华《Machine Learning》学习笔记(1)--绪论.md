# 第1章 绪论

机器学习是目前信息技术中最激动人心的方向之一，其应用已经深入到生活的各个层面且与普通人的日常生活密切相关。
本文为清华大学最新出版的《机器学习》教材的Learning Notes，书作者是南京大学周志华教授。
本篇主要介绍了该教材前两个章节的知识点以及自己一点浅陋的理解。

## 1.1 引言

傍晚小街路面上沁出微雨后的湿润，和熙的细风吹来，抬头看看天边的晚霞，嗯，明天又是一个好天气。
走到水果摊旁，挑了个根蒂蜷缩、敲起来声音浊响的青绿西瓜，一边满心期待着皮薄肉厚瓢甜的爽落感，一边愉快地想着，这学期狠下了工夫，基础概念弄得清清楚楚，算法作业也是信手拈来，这门课成绩一定差不了！
哈哈，也希望自己这学期的machine learning课程取得一个好成绩！

### 机器学习的定义

正如我们根据过去的经验来判断明天的天气，吃货们希望从购买经验中挑选一个好瓜，那能不能让计算机帮助人类来实现这个呢？
机器学习正是这样的一门学科，人的“经验”对应计算机中的“数据”，让计算机来学习这些经验数据，生成一个算法模型，在面对新的情况中，计算机便能作出有效的判断，这便是机器学习。
可以说机器学习是研究关于“学习算法”的学问。

另一本经典教材的作者Mitchell给出了一个形式化的定义，假设：

- $P$：计算机程序在某任务类T上的性能。
- $T$：计算机程序希望实现的任务类。
- $E$：表示经验，即历史的数据集。

若该计算机程序通过利用经验$E$在任务$T$上获得了性能$P$的改善，则称该程序对$E$进行了学习。

## 1.2 基本术语

假设我们收集了一批西瓜的数据，例如：（色泽=青绿;根蒂=蜷缩;敲声=浊响)， (色泽=乌黑;根蒂=稍蜷;敲声=沉闷)， (色泽=浅自;根蒂=硬挺;敲声=清脆)……每对括号内是一个西瓜的记录，定义：

- 所有记录的集合为：数据集（data set）。
- 每一条记录为：一个实例（instance）或样本（sample）。
- 例如：色泽或敲声，单个的特点为特征（feature）或属性（attribute）。
- 对于一条记录，如果在坐标轴上表示，每个西瓜都可以用坐标轴中的一个点表示，一个点也是一个向量，例如（青绿，蜷缩，浊响），即每个西瓜为：一个特征向量（feature vector）。
- 一个样本的特征数为：维数（dimensionality），该西瓜的例子维数为3，当维数非常大时，也就是现在说的“维数灾难”。

计算机程序学习经验数据生成算法模型的过程中，每一条记录称为一个“训练样本”，同时在训练好模型后，我们希望使用新的样本来测试模型的效果，则每一个新的样本称为一个“测试样本”。
定义：

- 所有训练样本的集合为：训练集（training set），[特殊]。
- 所有测试样本的集合为：测试集（test set），[一般]。  
- 机器学习出来的模型适用于新样本的能力为：泛化能力（generalization），即从特殊到一般。

- 关于示例结果的信息，例如“好瓜”，称为“标记”（label）。
- 拥有了标记信息的示例，称为“样例”（example）。
- 所有标记的集合，称为“标记空间”（label space）或“”输出空间。

西瓜的例子中，我们是想计算机通过学习西瓜的特征数据，训练出一个决策模型，来判断一个新的西瓜是否是好瓜。
可以得知我们预测的是：西瓜是好是坏，即好瓜与差瓜两种，是离散值。
同样地，也有通过历年的气象资料，来预测未来某天的气温，气温则是连续值。
定义：

- 预测值为离散值的问题为：分类（classification）。
- 预测值为连续值的问题为：回归（regression）。

我们预测西瓜是否是好瓜的过程中，很明显对于训练集中的西瓜，我们事先已经知道了该瓜是否是好瓜，学习器通过学习这些好瓜或差瓜的特征，从而总结出规律，即训练集中的西瓜我们都做了标记，称为标记信息。
但也有没有标记信息的情形，例如：我们想将一堆西瓜根据特征分成两个小堆，使得某一堆的西瓜尽可能相似，即都是好瓜或差瓜，对于这种问题，我们事先并不知道西瓜的好坏，样本没有标记信息。
定义：

- 训练数据有标记信息的学习任务为：监督学习（supervised learning，亦称有导师学习），容易知道上面所描述的分类和回归都是监督学习的范畴。
- 训练数据没有标记信息的学习任务为：无监督学习（unsupervised learning，亦称无导师学习），常见的有聚类和关联规则。

机器学习通常假设样本空间中全体样本服从一个未知的“分布”（distribution），我们获得的每个样本都是独立地从这个分布上采样取得的，即“独立同分布”（independent and identically distributed, i.e. *i.i.d.*）。

## 1.3 假设空间

科学推理两大手段：归纳（induction）和演绎（deduction）。
前者是从特殊到一般的“泛化”（generalization）过程，后者是从一般到特殊的“特化”（specialization）过程。
“从样例中学习”是一个归纳过程，亦称“归纳学习”（inductive learning）。

广义的归纳学习大体相当于从样例中学习。
狭义的归纳学习要求从训练数据中学的概念（concept），亦称“概念学习”或“概念形成”。

假设空间：属性可能取值构成的空间。
通过一定策略对假设空间进行搜索，不断删除与正例不一致的假设，和（或）与反例一致的假设，最终获得与训练集一致的假设，这就是学习结果。

现实中通常样本有限，而假设空间很大，可能有多个假设与训练集一致。
这些与训练集一致的“假设集合”，称为“版本空间”（version space）。

## 1.4 归纳偏好

归纳偏好（inductive bias）：机器学习算法在学习过程中对某种类型假设的偏好。亦称“偏好”。

任何一个有效的机器学习算法必有其归纳偏好，否则它将被假设空间中看似在训练集上“等效”的假设所迷惑，而无法产生确定的学习结果。

归纳偏好可看作学习算法自身在一个可能很庞大的假设空间里对假设进行选择的启发式或“价值观”。
可选的一般性原则，例如：“奥卡姆剃刀”：若有多个假设与观察一致，选最简单的那个。

归纳偏好对应了学习算法本身所做出的关于“什么样的模型更好”的假设。
在具体的现实问题中，这个假设是否成立，即算法的归纳偏好是否与问题本身匹配，大多数时候直接决定了算法能否取得好性能。

“没有免费的午餐”定理（No Free Lunch Theorem，i.e. NFL）：不同的算法期望性能相同。

NFL前提：

- 假设所有“问题”出现的机会相同、或所有问题同等重要。
  （这个前提在实际情形中并不常常成立。通常我们只关心某一具体问题的解决方案，不在意这个方案对其他问题的效果）
- 假设希望学习的真实目标函数 $f$ 均匀分布。

NFL最重要的寓意：讨论学习算法的相对优劣，必须结合具体问题。
否则如果讨论所有潜在问题，则所有的学习算法一样好（坏）。

## 1.5 发展历程

机器学习是人工智能（artificial intelligence）研究发展到一定阶段的必然产物。

机器学习的若干发展阶段：

- 推理期。
  二十世纪五十年代到七十年代初。
  基于符号知识表示、通过获取演绎推理技术。
- 知识期。
  二十世纪八十年代。
  基于符号知识表示、通过获取和利用领域知识来建立专家系统。
- 学习期。
  - 二十世纪八十年代开始，流行基于符号知识表示，其代表包括决策树（decision tree，以信息论为基础，以信息熵为最小化目标，直接模拟了人类对概念进行判定的树形流程）和基于逻辑的学习（代表为归纳逻辑程序设计，Inductive Logic Programming，i.e. ILP）。
  但这些方法的表示能力过强，也导致了问题规模稍大就难以学习。
  
  - 二十世纪九十年代中期之前，另一主流技术是基于神经网络的连接主义学习（例如Hopfield网络、BP网络）。
  连接主义学习产生的是“黑箱”模型，其参数众多，而且调参缺乏理论指导。

  - 二十世纪九十年代中期之后，统计学习（statistical learning）迅速兴起。
  其代表为支持向量机（Support Vector Machine，i.e. SVM）和“核方法”（kernel methods，逐渐成为机器学习的基本内容之一）。
  统计学习与连接主义学习有密切联系。

  - 二十一世纪初，连接主义学习卷土重来，代表为“深度学习”，即很多层的神经网络。
  深度学习缺乏严格的理论基础，但是显著降低了机器学习应用者的门槛。
  深度学习火热的两个基本原因：数据量变大、计算能力变强。

## 1.6 应用现状

- 计算机分支学科：尤其是计算机视觉、自然语言处理等“计算机应用技术”。
- 交叉学科：生物信息学

大数据时代三大关键技术：机器学习（提供数据分析能力）、云计算（提供数据处理能力）、众包（crowdsourcing，提供数据标记能力）。

统计学主要是通过机器学习对数据挖掘发挥影响。

数据挖掘的两大支撑：机器学习领域+数据库领域。

## 1.7 阅读材料

[Mitchell, 1997][Duda et al., 2001; Alpaydin, 2004; Flach, 2012] 等等。

机器学习重要会议：国际机器学习会议（ICML）、国际神经信息处理系统会议（NIPS）和国际学习理论会议（COLT）等等。
重要期刊：*Journal of machine Learning Research*，*Machine Learning* 等等。

人工智能重要会议：IJCAI、AAAI等等。
重要期刊：*Artificial Intelligence*、*Journal of Artificial Intelligence Research* 等等。

数据挖掘重要会议：KDD、ICDM等等。
重要期刊：*ACM Transactions on Knowledge Discovery from Data*、*Data Mining and Knowledge Discovery* 等等。

计算机视觉与模式识别重要会议：CVPR等等。
重要期刊：*IEEE Transactions on Pattern Analysis and Machine Learning Intelligence* 等等。

神经网络和统计学领域重要期刊：*Neural Computation*、*IEEE Transactions on Neural Networks and Learning Systems*、*Annals of Statistics* 等等。
